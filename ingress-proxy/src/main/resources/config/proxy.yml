---
# Reverse Proxy Handler Configuration

# If HTTP 2.0 protocol will be used to connect to target servers. Only if all host are using https
# and support the HTTP2 can set this one to true. 
http2Enabled: ${proxy.http2Enabled:false}

# Target URIs. Use comma separated string for multiple hosts. You can have mix http and https and
# they will be load balanced. If the host start with https://, then TLS context will be created. 
hosts: ${proxy.hosts:http://localhost:8080}

# Connections per thread to the target servers
connectionsPerThread: ${proxy.connectionsPerThread:20}

# Max request time in milliseconds before timeout
maxRequestTime: ${proxy.maxRequestTime:1000}

# Rewrite Host Header with the target host and port and write X_FORWARDED_HOST with original host
rewriteHostHeader: ${proxy.rewriteHostHeader:true}

# Reuse XForwarded for the target XForwarded header
reuseXForwarded: ${proxy.reuseXForwarded:false}

# Max Connection Retries
maxConnectionRetries: ${proxy.maxConnectionRetries:3}

# The max queue size for the requests if there is no connection to the downstream API in the connection pool.
# The default value is 0 that means there is queued requests. As we have maxConnectionRetries, there is no
# need to use the request queue to increase the memory usage. It should only be used when you see 503 errors
# in the log after maxConnectionRetries to accommodate slow backend API.
maxQueueSize: ${proxy.maxQueueSize:0}

# Decode the JWT token claims and forward to the backend api in the form of json string
forwardJwtClaims: ${proxy.forwardJwtClaims:false}

# When LightProxyHandler is used in the http-sidecar or light-gateway, it can collect the metrics info for the
# total response time of the downstream API. With this value injected, users can quickly determine how much
# time the http-sidecar or light-gateway handlers spend and how much time the downstream API spends, including
# the network latency. By default, it is false, and metrics will not be collected and injected into the metrics
# handler configured in the request/response chain.
metricsInjection: ${proxy.metricsInjection:false}
# When the metrics info is injected into the metrics handler, we need to pass a metric name to it so that the
# metrics info can be categorized in a tree structure under the name. By default, it is proxy-response, and
# users can change it.
metricsName: ${proxy.metricsName:proxy-response}
