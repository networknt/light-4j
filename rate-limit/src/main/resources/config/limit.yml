---
# Rate Limit Handler Configuration

# If this handler is enabled or not. It is disabled by default as this handle might be in
# most http-sidecar, light-proxy and light-router instances. However, it should only be used
# internally to throttle request for a slow backend service or externally for DDoS attacks.
enabled: ${limit.enabled:false}
# Maximum concurrent requests allowed at a given time. If this number is exceeded, new requests
# will be queued. It must be greater than 1 and should be set based on your use case. Be aware
# it is concurrent requests not the number of request per second. Light-4j server can handle
# millions of request per seconds. With 2 concurrent requests, the petstore API can still handle
# hundreds or even thousands requests per second.
concurrentRequest: ${limit.concurrentRequest:2}
# Overflow request queue size. -1 means there is no limit on the queue size and this should
# only be used in the corporate network for throttling. For Internet facing service, set it
# to a small value to prevent DDoS attacks. New requests will be dropped with 503 response
# code returned if the queue is full.
queueSize: ${limit.queueSize:-1}
# If the rate limit is exposed to the Internet to prevent DDoS attacks, it will return 503
# error code to trick the DDoS client/tool to stop the attacks as it considers the server
# is down. However, if the rate limit is used internally to throttle the client requests to
# protect a slow backend API, it will return 429 error code to indicate too many requests
# for the client to wait a grace period to resent the request. By default, 503 is returned.
errorCode: ${limit.errorCode:503}
